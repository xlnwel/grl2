import functools
import numpy as np
import ray

from core.builder import ElementsBuilder
from tools.log import do_logging
from core.utils import set_seed, save_code
from core.utils import configure_gpu
from core.typing import ModelPath
from tools.store import StateStore
from tools.utils import modify_config
from tools.timer import Every, Timer
from tools import pkg
from algo.ppo.run import *


def train(
  configs, 
  agents, 
  runner, 
  buffers
):
  config = configs[0]
  routine_config = config.routine.copy()
  collect_fn = pkg.import_module(
    'elements.utils', algo=routine_config.algorithm).collect
  collects = [functools.partial(collect_fn, buffer) for buffer in buffers]

  step = agents[0].get_env_step()
  # print("Initial running stats:", 
  #   *[f'{k:.4g}' for k in agent.get_rms_stats() if k])
  to_record = Every(
    routine_config.LOG_PERIOD, 
    start=step, 
    init_next=step != 0, 
    final=routine_config.MAX_STEPS)
  rt = Timer('run')
  tt = Timer('train')

  for agent in agents:
    agent.store(**{'time/log_total': 0, 'time/log': 0})

  do_logging('Training starts...')
  train_step = agents[0].get_train_step()
  env_stats = runner.env_stats()
  steps_per_iter = env_stats.n_envs * routine_config.n_steps
  all_aids = list(range(len(agents)))
  while step < routine_config.MAX_STEPS:
    # do_logging(f'start a new iteration with step: {step} vs {routine_config.MAX_STEPS}')
    start_env_step = agents[0].get_env_step()
    for b in buffers:
      assert b.size() == 0, b.size()
    with rt:
      env_outputs = runner.run(
        routine_config.n_steps, 
        agents, collects, 
        [], all_aids)
      for i, buffer in enumerate(buffers):
        data = buffer.get_data({
          'state_reset': env_outputs[i].reset
        })
        buffer.move_to_queue(data)

    for b in buffers:
      assert b.ready(), (b.size(), len(b._queue))
    step += steps_per_iter

    time2record = to_record(step)

    # train agents
    for agent in agents:
      start_train_step = agent.get_train_step()
      with tt:
        agent.train_record()
      
      train_step = agent.get_train_step()
      assert train_step != start_train_step, (start_train_step, train_step)
      agent.set_env_step(step)
      agent.trainer.sync_lookahead_params()
    
    if time2record:
      with Timer('log'):
        for agent in agents:
          agent.store(**{
            'stats/train_step': train_step,
            'time/fps': (step-start_env_step)/rt.last(), 
            'time/tps': (train_step-start_train_step)/tt.last(),
          }, 
          **Timer.all_stats())
          agent.record(step=step)
          agent.save()
    # do_logging(f'finish the iteration with step: {step}')


def main(configs, train=train):
  configs = configure_gpu(configs)
  config = configs[0]
  seed = config.get('seed')
  set_seed(seed)

  use_ray = config.env.get('n_runners', 1) > 1 or config.routine.get('EVAL_PERIOD', False)
  if use_ray:
    from tools.ray_setup import sigint_shutdown_ray
    ray.init(num_cpus=config.env.n_runners)
    sigint_shutdown_ray()

  runner = Runner(config.env)

  # load agents
  env_stats = runner.env_stats()
  env_stats.n_envs = config.env.n_runners * config.env.n_envs
  agents = []
  buffers = []
  root_dir = config.root_dir
  model_name = config.model_name
  for i, c in enumerate(configs):
    assert c.aid == i, (c.aid, i)
    if f'a{i}' in model_name:
      new_model_name = model_name
    else:
      new_model_name = os.path.join(model_name, f'a{i}')
    modify_config(
      configs[i], 
      model_name=new_model_name, 
    )
    builder = ElementsBuilder(
      configs[i], 
      env_stats, 
      to_save_code=False, 
      max_steps=config.routine.MAX_STEPS
    )
    elements = builder.build_agent_from_scratch()
    agents.append(elements.agent)
    buffers.append(elements.buffer)
  save_code(ModelPath(root_dir, model_name))

  train(configs, agents, runner, buffers)

  do_logging('Training completed')
